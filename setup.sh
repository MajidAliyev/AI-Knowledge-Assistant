#!/bin/bash

echo "ğŸš€ Setting up Personal AI Knowledge Assistant..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed. Please install it from https://ollama.ai"
    exit 1
fi

echo "âœ… Ollama found"

# Setup backend
echo "ğŸ“¦ Setting up backend..."
cd backend
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
cd ..

# Setup frontend
echo "ğŸ“¦ Setting up frontend..."
cd frontend
npm install
cd ..

# Create necessary directories
echo "ğŸ“ Creating directories..."
mkdir -p documents
mkdir -p chroma_db

# Check if models are available
echo "ğŸ” Checking Ollama models..."
if ! ollama list | grep -q "mistral\|llama3\|phi3"; then
    echo "âš ï¸  No models found. Pulling mistral model..."
    ollama pull mistral
fi

# Pull embedding model if needed
if ! ollama list | grep -q "nomic-embed-text"; then
    echo "ğŸ“¥ Pulling embedding model..."
    ollama pull nomic-embed-text
fi

echo ""
echo "âœ… Setup complete!"
echo ""
echo "To start the application:"
echo "  1. Start backend: cd backend && source venv/bin/activate && uvicorn main:app --reload"
echo "  2. Start frontend: cd frontend && npm run dev"
echo ""
echo "Then open http://localhost:5173 in your browser"

